{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv('features.csv', index_col='match_id')\n",
    "df_test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "df_copy = deepcopy(df) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "col = ['duration', 'radiant_win', 'tower_status_radiant', \"tower_status_dire\",\n",
    "       'barracks_status_radiant', 'barracks_status_dire']\n",
    "\n",
    "# удалил признаки связанные с итогами матча\n",
    "df.drop(col, axis=1, inplace=True, errors='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of row: first_blood_time count: 77677\n",
      "Number of row: first_blood_team count: 77677\n",
      "Number of row: first_blood_player1 count: 77677\n",
      "Number of row: first_blood_player2 count: 53243\n",
      "Number of row: radiant_bottle_time count: 81539\n",
      "Number of row: radiant_courier_time count: 96538\n",
      "Number of row: radiant_flying_courier_time count: 69751\n",
      "Number of row: radiant_first_ward_time count: 95394\n",
      "Number of row: dire_bottle_time count: 81087\n",
      "Number of row: dire_courier_time count: 96554\n",
      "Number of row: dire_flying_courier_time count: 71132\n",
      "Number of row: dire_first_ward_time count: 95404\n"
     ]
    }
   ],
   "source": [
    "# посчитал количество пропусков\n",
    "c = df.count()\n",
    "\n",
    "j = 0\n",
    "names_count = np.empty(12)\n",
    "for i in range(len(c)):\n",
    "    if c[i] < 97230:\n",
    "        names_count[j] = i # записал название признаков имеющих пропуски \n",
    "        j += 1\n",
    "        print('Number of row:', c.index[i], 'count:', c[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "mean_df = df.mean(axis=0)\n",
    "\n",
    "# df.fillna(0.00000000001, inplace=True) # пробовал заменять пропуски\n",
    "# на очень маленькое значение\n",
    "\n",
    "\n",
    "# заменяю пропуски на среднее значение по этому столбцу\n",
    "\n",
    "for i in range(len(names_count)):\n",
    "    # print(c.index[names_count[i]], c[int(names_count[i])])\n",
    "    df[c.index[names_count[i]]].fillna(mean_df[int(names_count[i])], inplace=True)\n",
    "    # print(df[c.index[names_count[i]]])\n",
    "    # print(\"---------------------------------------------------------------\")\n",
    "\n",
    "# df.fillna(0, axis=0, inplace=True) # пробовал заменять пропуски на нули    \n",
    "\n",
    "\n",
    "# уменьшал обучающую выборку, засчет этого нашел ответ на вопрос\n",
    "# о том как ускорить время обучения градиентного бустинга\n",
    "\n",
    "# x_train, x_test, y_train, y_test =  train_test_split(df, df_copy['radiant_win'], test_size=0.6, random_state=241)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3786           17.44s\n",
      "         2           1.3730           16.80s\n",
      "         3           1.3680           16.18s\n",
      "         4           1.3634           15.60s\n",
      "         5           1.3592           15.00s\n",
      "         6           1.3547           14.39s\n",
      "         7           1.3503           13.80s\n",
      "         8           1.3464           13.21s\n",
      "         9           1.3425           12.62s\n",
      "        10           1.3385           12.02s\n",
      "        20           1.3091            6.07s\n",
      "        30           1.2891            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3781           18.37s\n",
      "         2           1.3725           17.69s\n",
      "         3           1.3674           16.92s\n",
      "         4           1.3628           16.56s\n",
      "         5           1.3585           15.89s\n",
      "         6           1.3539           15.19s\n",
      "         7           1.3498           14.52s\n",
      "         8           1.3454           13.83s\n",
      "         9           1.3413           13.16s\n",
      "        10           1.3374           12.49s\n",
      "        20           1.3071            6.11s\n",
      "        30           1.2870            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3787           17.54s\n",
      "         2           1.3731           16.99s\n",
      "         3           1.3681           16.53s\n",
      "         4           1.3636           15.87s\n",
      "         5           1.3588           15.28s\n",
      "         6           1.3541           14.66s\n",
      "         7           1.3501           14.04s\n",
      "         8           1.3456           13.42s\n",
      "         9           1.3414           12.78s\n",
      "        10           1.3376           12.16s\n",
      "        20           1.3079            6.03s\n",
      "        30           1.2875            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784           18.76s\n",
      "         2           1.3729           18.22s\n",
      "         3           1.3679           17.59s\n",
      "         4           1.3632           16.99s\n",
      "         5           1.3583           16.43s\n",
      "         6           1.3537           15.78s\n",
      "         7           1.3493           15.06s\n",
      "         8           1.3450           14.34s\n",
      "         9           1.3413           13.59s\n",
      "        10           1.3376           12.87s\n",
      "        20           1.3076            6.26s\n",
      "        30           1.2868            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3787           17.81s\n",
      "         2           1.3732           17.09s\n",
      "         3           1.3683           16.50s\n",
      "         4           1.3637           15.86s\n",
      "         5           1.3589           15.21s\n",
      "         6           1.3547           14.60s\n",
      "         7           1.3502           13.99s\n",
      "         8           1.3460           13.47s\n",
      "         9           1.3420           12.89s\n",
      "        10           1.3382           12.25s\n",
      "        20           1.3088            6.06s\n",
      "        30           1.2886            0.00s\n",
      "Time elapsed: 0:01:31.963356\n",
      "0.6891750450655258\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "\n",
    "# использовал закоментированный код ниже чтобы проверить качество и время обучения\n",
    "# для разного кол-ва деревьев\n",
    "\n",
    "# для обучения использовал также выше указанную уменьшенную обучающую выборку с\n",
    "# разнымми значениями\n",
    "# и пробовал уменьшить max_depth - время обучения реально уменьшается\n",
    "\n",
    "# n_est = 10\n",
    "# for i in range(5):\n",
    "#     clf = GradientBoostingClassifier(n_estimators=n_est, verbose=True,\n",
    "#                                      random_state=241, max_depth=2)\n",
    "#     # clf.fit(x_train, y_train)\n",
    "#\n",
    "#     start_time = datetime.datetime.now()\n",
    "#\n",
    "#     # gbc = np.mean(cross_val_score(clf, x_train, np.ravel(y_train, order = 'C'), cv=kf, scoring='roc_auc'))\n",
    "#     gbc = np.mean(cross_val_score(clf, df, df_copy['radiant_win'],\n",
    "#                                   cv=kf, scoring='roc_auc'))\n",
    "#\n",
    "#     n_est = n_est + 10\n",
    "#     print('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "#     print(gbc, n_est)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=30, verbose=True, random_state=241)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "gbc = np.mean(cross_val_score(clf, df, df_copy['radiant_win'] ,\n",
    "                              cv=kf, scoring='roc_auc'))\n",
    "\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "print(gbc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:01.940498\n",
      "0.7167263303131431\n"
     ]
    }
   ],
   "source": [
    "names = df.columns\n",
    "scal = preprocessing.StandardScaler()\n",
    "df_scaled = scal.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=names)\n",
    "\n",
    "reg = LogisticRegression(penalty='l2', C=0.01, random_state=241)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "lg = np.mean(cross_val_score(reg, df_scaled, df_copy['radiant_win'],\n",
    "                             cv=kf, scoring='roc_auc'))\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "\n",
    "print (lg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:02.226392\n",
      "0.716783013898749\n"
     ]
    }
   ],
   "source": [
    "# убираю категориальные признаки \n",
    "coll = ['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', \n",
    "        'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "\n",
    "df_scaled.drop(coll, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "lg_1 = np.mean(cross_val_score(reg, df_scaled, df_copy['radiant_win'],\n",
    "                               cv=kf, scoring='roc_auc'))\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "\n",
    "print (lg_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# ниже код собирает мешок слов после подсчета количества уникальных героев \n",
    "# и добавляем новые признаки в обучающую выборку\n",
    "\n",
    "hero_count = pd.unique(df[['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                           'd1_hero', 'd3_hero', 'd4_hero', 'd5_hero']].values.ravel())\n",
    "\n",
    "x_pick = np.zeros((df.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(df.index):\n",
    "    for p in range(5):\n",
    "        x_pick[i, df.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        x_pick[i, df.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "x_pick = pd.DataFrame(x_pick)\n",
    "data = np.concatenate([df_scaled, x_pick], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:06.154195\n",
      "0.7518403366123803\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "lg_2 = np.mean(cross_val_score(reg, data, df_copy['radiant_win'], cv=kf, scoring='roc_auc'))\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "\n",
    "print (lg_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# далее проделывается все те же преобразования c обучающей выборкой\n",
    "# только для df_test\n",
    "c_tst = df_test.count()\n",
    "\n",
    "j = 0\n",
    "names_tst_count = np.empty(12)\n",
    "for i in range(len(c_tst)):\n",
    "    if c_tst[i] < 17177:\n",
    "        names_tst_count [j] = i\n",
    "        j += 1\n",
    "        # print('Number of row:', c_tst.index[i], 'count:', c_tst[i])\n",
    "\n",
    "mean_tst_df = df_test.mean(axis=0) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "for i in range(len(names_tst_count)):\n",
    "    df_test[c_tst.index[names_tst_count[i]]].fillna(mean_tst_df[int(names_tst_count[i])], inplace=True)\n",
    "\n",
    "df_tst_scaled = scal.fit_transform(df_test)\n",
    "df_tst_scaled = pd.DataFrame(df_tst_scaled, columns=names)\n",
    "\n",
    "df_tst_scaled.drop(coll, axis=1, inplace=True, errors='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "x_pick_tst = np.zeros((df_test.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(df_test.index):\n",
    "    for p in range(5):\n",
    "        x_pick_tst[i, df_test.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        x_pick_tst[i, df_test.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "x_pick_tst = pd.DataFrame(x_pick_tst)\n",
    "data_tst = np.concatenate([df_tst_scaled, x_pick_tst], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9959619261912386\n",
      "0.008616422488704298\n"
     ]
    }
   ],
   "source": [
    "# обучаем логистическую регрессию на преобразованных данных\n",
    "reg.fit(data, df_copy['radiant_win'])\n",
    "final = reg.predict_proba(data_tst)[:, 1]\n",
    "\n",
    "print (final.max())\n",
    "print (final.min())\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
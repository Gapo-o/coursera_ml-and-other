{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     true  pred\n",
      "0       1     0\n",
      "1       1     1\n",
      "2       1     1\n",
      "3       0     0\n",
      "4       1     1\n",
      "..    ...   ...\n",
      "195     0     0\n",
      "196     0     0\n",
      "197     1     0\n",
      "198     0     1\n",
      "199     0     0\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, \\\n",
    "    precision_recall_curve\n",
    "\n",
    "df = pd.read_csv('classification.csv')\n",
    "\n",
    "print (df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['true'] == 1:\n",
    "        if row['true'] == row['pred']:\n",
    "            TP += 1\n",
    "            # print (row['true'], row['pred'])\n",
    "        else:\n",
    "            FN += 1\n",
    "            # print (row['true'], row['pred'])\n",
    "    elif row['true'] == 0:\n",
    "        if row['true'] == row['pred']:\n",
    "            TN += 1\n",
    "            # print (row['true'], row['pred'])\n",
    "        else: \n",
    "            FP += 1\n",
    "            # print (row['true'], row['pred'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 34 59 64\n",
      "0.535\n",
      "0.5584415584415584\n",
      "0.4215686274509804\n",
      "0.48044692737430167\n",
      "\n",
      "0.535\n",
      "0.5584415584415584\n",
      "0.4215686274509804\n",
      "0.48044692737430167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gapo_o/Documents/shad/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass normalize=2 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/home/gapo_o/Documents/shad/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass labels=2 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "print(TP, FP, FN, TN)\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FN + FP)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "F_mera = (2 * precision * recall) / (precision +recall)\n",
    "\n",
    "print (accuracy)\n",
    "print (precision)\n",
    "print (recall)\n",
    "print (F_mera)\n",
    "\n",
    "print()\n",
    "\n",
    "print (accuracy_score(df.true, df.pred, 2))\n",
    "print (precision_score(df.true, df.pred, 2))\n",
    "print (recall_score(df.true, df.pred, 2))\n",
    "print (f1_score(df.true, df.pred, 2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     true  score_logreg  score_svm  score_knn  score_tree\n",
      "0       0      0.683832   0.145976   0.787063    0.500000\n",
      "1       1      0.801966   0.239511   1.000000    0.833333\n",
      "2       0      0.382315  -0.245701   0.000000    0.000000\n",
      "3       1      0.506797  -0.137058   0.000000    0.105263\n",
      "4       1      0.488781  -0.154148   0.000000    0.105263\n",
      "..    ...           ...        ...        ...         ...\n",
      "195     0      0.573801  -0.088203   0.284192    0.400000\n",
      "196     0      0.624422  -0.012315   0.205437    0.400000\n",
      "197     1      0.425538  -0.135673   0.382351    0.700000\n",
      "198     0      0.905270   0.583806   1.000000    1.000000\n",
      "199     0      0.275594  -0.422160   0.743567    0.642857\n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('scores.csv')\n",
    "\n",
    "print (data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719187675070028\n",
      "0.7086834733893557\n",
      "0.6351540616246498\n",
      "0.6919267707082833\n"
     ]
    }
   ],
   "source": [
    "a = sklearn.metrics.roc_auc_score(data.true, data.score_logreg)\n",
    "print (a)\n",
    "\n",
    "b = sklearn.metrics.roc_auc_score(data.true, data.score_svm)\n",
    "print (b)\n",
    "\n",
    "c = sklearn.metrics.roc_auc_score(data.true, data.score_knn)\n",
    "print (c)\n",
    "\n",
    "d = sklearn.metrics.roc_auc_score(data.true, data.score_tree)\n",
    "print (d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.6517857142857143\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "precision_a, reccall_a, thresholds_a = precision_recall_curve (data.true, data.score_logreg)\n",
    "\n",
    "precision_b, reccall_b, thresholds_b = precision_recall_curve (data.true, data.score_svm)\n",
    "\n",
    "precision_c, reccall_c, thresholds_c = precision_recall_curve (data.true, data.score_knn)\n",
    "\n",
    "precision_d, reccall_d, thresholds_d = precision_recall_curve (data.true, data.score_tree)\n",
    "\n",
    "a_max = 0\n",
    "a_iter = 0\n",
    "\n",
    "b_max = 0\n",
    "b_iter = 0\n",
    "\n",
    "c_max = 0\n",
    "c_iter = 0\n",
    "\n",
    "d_max = 0\n",
    "d_iter = 0\n",
    "\n",
    "for i in range (len(precision_a)):\n",
    "    if reccall_a[i] > 0.7:\n",
    "        if a_max <= precision_a[i]:\n",
    "            a_max = precision_a[i]\n",
    "            a_iter = i\n",
    "\n",
    "for i in range (len(precision_b)):\n",
    "    if reccall_b[i] > 0.7:\n",
    "        if b_max <= precision_b[i]:\n",
    "            b_max = precision_b[i]\n",
    "            b_iter = i\n",
    "\n",
    "for i in range (len(precision_c)):\n",
    "    if reccall_c[i] > 0.7:\n",
    "        if c_max <= precision_c[i]:\n",
    "            c_max = precision_c[i]\n",
    "            c_iter = i\n",
    "\n",
    "for i in range (len(precision_d)):\n",
    "    if reccall_d[i] > 0.7:\n",
    "        if d_max <= precision_d[i]:\n",
    "            d_max = precision_d[i]\n",
    "            d_iter = i    \n",
    "\n",
    "maximum = max (a_max, b_max, c_max, d_max)\n",
    "print(maximum)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}